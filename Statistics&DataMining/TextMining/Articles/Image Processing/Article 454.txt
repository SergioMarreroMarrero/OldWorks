A Benchmark and Comparative Study of Video-Based Face Recognition on COX Face Database,

# Face recognition with still face images has been widely studied, while the research on video-based face recognition is inadequate relatively, especially in terms of benchmark datasets and comparisons. Real-world video-based face recognition applications require techniques for three distinct scenarios: 1) Videoto-Still (V2S); 2) Still-to-Video (S2V); and 3) Video-to-Video (V2V), respectively, taking video or still image as query or target. To the best of our knowledge, few datasets and evaluation protocols have benchmarked for all the three scenarios. In order to facilitate the study of this specific topic, this paper contributes a benchmarking and comparative study based on a newly collected still/video face database, named COX1 Face DB. Specifically, we make three contributions. First, we collect and release a largescale still/video face database to simulate video surveillance with three different video-based face recognition scenarios (i.e., V2S, S2V, and V2V). Second, for benchmarking the three scenarios designed on our database, we review and experimentally compare a number of existing set-based methods. Third, we further propose a novel Point-to-Set Correlation Learning (PSCL) method, and experimentally show that it can be used as a promising baseline method for V2S/S2V face recognition on COX Face DB. Extensive experimental results clearly demonstrate that video-based face recognition needs more efforts, and our COX Face DB is a good benchmark database for evaluation.

{face recognition;video signal processing;COX face database;PSCL method;novel point-to-set correlation learning method;real-world video-based face recognition;still face images;still-to-video scenario;video-to-still scenario;video-to-video scenario;Databases;Face;Face recognition;Protocols;Testing;Video equipment;Video sequences;COX Face DB;Point-to-Set Correlation Learning;Still-to-Video;Video-based face recognition;Video-to-Still;Video-to-Video;benchmarking;point-to-set correlation learning;still-to-video;video-to-still;video-to-video},




Constructing a Nonnegative Low-Rank and Sparse Graph With Data-Adaptive Features,

# This paper aims at constructing a good graph to discover the intrinsic data structures under a semisupervised learning setting. First, we propose to build a nonnegative low-rank and sparse (referred to as NNLRS) graph for the given data representation. In particular, the weights of edges in the graph are obtained by seeking a nonnegative low-rank and sparse reconstruction coefficients matrix that represents each data sample as a linear combination of others. The so-obtained NNLRS-graph captures both the global mixture of subspaces structure (by the low-rankness) and the locally linear structure (by the sparseness) of the data, hence it is both generative and discriminative. Second, as good features are extremely important for constructing a good graph, we propose to learn the data embedding matrix and construct the graph simultaneously within one framework, which is termed as NNLRS with embedded features (referred to as NNLRS-EF). Extensive NNLRS experiments on three publicly available data sets demonstrate that the proposed method outperforms the state-of-the-art graph construction method by a large margin for both semisupervised classification and discriminative analysis, which verifies the effectiveness of our proposed method.

{feature extraction;image classification;image reconstruction;image representation;learning (artificial intelligence);sparse matrices;NNLRS graph;data adaptive feature;data embedding matrix;data representation;discriminative analysis;nonnegative low-rank and sparse graph;semisupervised classification;semisupervised learning setting;sparse reconstruction coefficient matrix;Algorithm design and analysis;Complexity theory;Dictionaries;Noise;Optimization;Robustness;Sparse matrices;Data Embedding;Graph Construction;Low-Rank and Sparse Representation;Semi-Supervised Learning;data embedding;low-rank and sparse representation;semi-supervised learning},




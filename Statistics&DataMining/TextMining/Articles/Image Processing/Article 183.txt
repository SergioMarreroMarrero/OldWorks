Online Space-Variant Background Modeling With Sparse Coding,

# In this paper, we propose a sparse coding approach to background modeling. The obtained model is based on dictionaries which we learn and keep up to date as new data are provided by a video camera. We observe that, without dynamic events, video frames may be seen as noisy data belonging to the background. Over time, such background is subject to local and global changes due to variable illumination conditions, camera jitter, stable scene changes, and intermittent motion of background objects. To capture the locality of some changes, we propose a space-variant analysis where we learn a dictionary of atoms for each image patch, the size of which depends on the background variability. At run time, each patch is represented by a linear combination of the atoms learnt online. A change is detected when the atoms are not sufficient to provide an appropriate representation, and stable changes over time trigger an update of the current dictionary. Even if the overall procedure is carried out at a coarse level, a pixel-wise segmentation can be obtained by comparing the atoms with the patch corresponding to the dynamic event. Experiments on benchmarks indicate that the proposed method achieves very good performances on a variety of scenarios. An assessment on long video streams confirms our method incorporates periodical changes, as the ones caused by variations in natural illumination. The model, fully data driven, is suitable as a main component of a change detection system.

{image representation;image segmentation;jitter;video coding;video streaming;atom dictionary learning;background object intermittent motion;background variability;camera jitter;image patch representation;linear combination;noisy data;online space-variant background modeling;pixel-wise segmentation;space-variant analysis;sparse coding approach;variable illumination condition;video camera;video frame;video stream;Adaptation models;Cameras;Complexity theory;Dictionaries;Image reconstruction;Streaming media;Training;Background subtraction;dictionary learning and sparse coding;representations;space-variant},




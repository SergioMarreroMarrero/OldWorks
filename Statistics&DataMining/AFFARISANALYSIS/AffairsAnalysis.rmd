---
title: "Infidelidades"
author: "UOC - Master BI - Business Analytics (Nombre Estudiante)"
date: "Marzo del 2017"
output:
  html_document:
    fig_height: 5
    fig_width: 7
    number_sections: yes
    theme: journal
    toc: yes
    toc_depth: 1
  pdf_document:
    toc: yes
  word_document: default
---

******
# Solucion a los ejercicios
******
# ¿Cual es la media, mediana y desviación muestral del número de infidelidades?

> Cargamos los datos

En esta celda cargamos los datos, cambiamos los nombres, y consultamos la muestra de los 10 primeros para tener una primera impresión.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
#data_directory <-file.choose()
rm(list=ls()) # Clean de workspace
data_directory <-  "/home/sergio/Escritorio/R/pec2datamining/Enunciado/affairs_def.csv"
X <- read.csv(data_directory, header = TRUE, sep = ",", fill = TRUE)


## Cambio de nombre de las variables
colnames(X)<- c("genre","age","married", "kids", "naffairs")

```

> Consultamos los datos cargados y mostramos un boxplot

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

head(X,10)
```

A continuacion consultamos los datos cargados. Comprobamos el tipo de datos de las variables naffairs y genre, y mostramos un boxplot con la distribucion de la variable naffais. Se observa en este que la mayoría de los datos se concentran en 0 infidelidades.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
class(X$naffairs)
class(X$genre)
boxplot(X$naffairs)

```

> 3. Decripcion de la muestra. Se calcula la media, mediana y la desviacion muestral de la variable naffairs


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
# Con esta instruccion podemos ver un resumen de los estadisticos
summary(X$naffairs)

# Calculamos los estadisticos solicitados
N <- nrow(X)
media_muestral <- mean(X$naffairs)
media_muestral
mediana_muestral <- median(X$naffairs)
mediana_muestral
desviacion_muestral <-  sqrt(var(X$naffairs))
desviacion_muestral
desviacion_media <- desviacion_muestral/sqrt(N)
desviacion_media

```

# ¿Cual es la media de infidelidades de la población con un intervalo de confianza del 99%?

> Suponiendo que conocemos la desvianción estandar de la poblacion
Para este ejercicio vamos a suponer que la desviación standar de la población es conocida. Por este motivmo podemos asumir que la media muestral sigue una distribución normal, pudiendo utilizar el estadístico z. Calculamos el intervalo de confianza requerido



```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
alpha = 0.005
error_norm <- qnorm(1-alpha)*desviacion_media # Calculamos el valor z y lo multiplicamos lo variancia de la media
int_media_max_norm <- media_muestral + error_norm # Calculamos el extremo derecho del intervalo de confianza
int_media_max_norm
int_media_min_norm <- media_muestral - error_norm # Calculamos el extremo izquiero del intervalo de confianza
int_media_min_norm
recorrido_norm = int_media_max_norm - int_media_min_norm
recorrido_norm
```

> Sin conocimiento de la varianza poblacional.
Suponiendo desconocida la varianza poblacional debemos usar la distribución de la media: t de student. Con lo cual:


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
error_t <- qt(1-alpha, df=N-1)*desviacion_media # Calculamos el valor z y lo multiplicamos lo variancia de la media
int_media_max_t <- media_muestral + error_t # Calculamos el extremo derecho del intervalo de confianza
int_media_max_t
int_media_min_t <- media_muestral - error_t # Calculamos el extremo izquiero del intervalo de confianza
int_media_min_t


recorrido_norm = int_media_max_t - int_media_min_t
recorrido_norm

```

> Comparar ambos intervalos de confianza. ¿Cual es más adecuado a los datos?

Se observa que el intervalo de la normal es ligeramente inferior, demostrando tener más certeza en la predicción del estadístico en cuestión. Esto es así porque hay más incertidumbre en el segundo caso, ya que en el primero se parte de la suposición del conocimiento de la varianza poblacional. Por este motivo la dispresión de las distribuciones t es algo mayor que la dispersión de la distribución normal (estandarizada), es decir, son más pesadas en las colas de la misma.
Dado que desconocemos la varianza poblacional, **lo recomendable sería utilizar la t de student**. Sin embargo, cabe mencionar que cuando el número de grados de libertad aumenta, la t d student se va pareciendo mas a la normal.

#3 ¿Hay correlación lineal entre los affairs del últmo año y los años de casados?##
## Explicar si se puede calcular la correlación lineal de Perason con los campos: genre y naffairs
La respuesta es no. El campo genre no es de tipo numérico.
Para visualizar las infidelidades masculinas y femeninas utilizaremos un boxplot separando por genero. En este obsevamos que sólo con la visualización de datos no tendríamos suficiente evidencia para decir que los efectos son distintos. Es decir, hay una ligera tendecia a que desde el género masculino haya más infidelidad, sin embargo la evidencia que hay viendo los datos no es suficiente para descartar que sea puramente una casualidad.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
boxplot(X$naffairs~ X$genre, data=ToothGrowth, notch=TRUE, 
  col=(c("gold","darkgreen")),
  main="Infidelidades", xlab="Sexo")

```



> Mostramos un scatter plot con las dos variables: naffairs y married para ver visualmente si hay correlacion lineal.

En primer lugar comprobamos que ambas clases son numéricas:


```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
class(X$naffairs)
class(X$married)

```

Hacemos scatterplot para visualizarlas y ploteamos:

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
class(X$naffairs)
class(X$married)
plot(X$married, X$naffairs)

```


>> Mostramos un scatter plot con las dos variables: naffairs y married para ver visualmente si hay correlacion lineal.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
cor(X$married, X$naffairs)
```

>> Interpreta y explica el resultado del coeficiente obtenido en relación al valor (más cercano en valor 
absoluto a 1 o a 0) y sobretodo al signo (positivo o negativo).  

Se observa que prácticamente no hay correlación entre estas variables. Por un lado el plot no muestra ninguna relación entre las variables. Por otro lado, el coeficiente de correlación lineal es de 0.26, lo cual indica una muy baja correlación, en todo caso positiva por ser mayor que cero.



# Regresión:  ¿Podemos  suponer  que  las  variables  de  edad  y  años  casados  son  unas  buenas  variables explicativas para poder predecir el comportamiento de la infidelidad? 


> Calcular  la  regresión  con  un  modelo  lineal,  donde  la  infidelidad  se  relaciona  con  las  variables  de edad de la persona y los años que lleva casado.  Usar la función lm de R. 
 

Intentamos explicar las infidelidades con dos variables, la edad de la persona y los años casados. Para ellos calculamos el modelo de regresion lineal.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

modelo_lineal <- lm(X$naffairs~X$age + X$married)
modelo_lineal
```

> Estimamos el número de infidelidades de una persona que tendría una edad de 39 años y 5 años casado, a partir de los coeficientes del modelo lineal calculado. 

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}


newEdad <- 39
newCasado <- 5
(intercepcion <- modelo_lineal$coefficients[[1]])
(covEdad <- modelo_lineal$coefficients[[2]])
(covCasado <- modelo_lineal$coefficients[[3]])
  
```

> Calcular el error cuadrático medio que comete el modelo a partir del cálculo de los residuos. 



```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
newFrame <- data.frame(X$age,X$married)
inf_predicted <- predict(modelo_lineal, newFrame)

residuos <- inf_predicted - X$naffairs
error_c_m <- sum((residuos^2))/N

summary(modelo_lineal)


```

> Mostrar el coeficiente de determinación del modelo lineal e interpretar el coeficiente. 

En estadística, el coeficiente de determinación, denominado R² y pronunciado R cuadrado, es un estadístico usado en el contexto de un modelo estadístico cuyo principal propósito es predecir futuros resultados o probar una hipótesis. El coeficiente determina la calidad del modelo para replicar los resultados, y la proporción de variación de los resultados que puede explicarse por el modelo.1
Hay varias definiciones diferentes para R² que son algunas veces equivalentes. Las más comunes se refieren a la regresión lineal. En este caso, el R² es simplemente el cuadrado del coeficiente de correlación de Pearson, lo cual es sólo cierto para la regresión lineal simple. Si existen varios resultados para una única variable, es decir, para una X existe una Y, Z... el coeficiente de determinación resulta del cuadrado del coeficiente de determinación múltiple. (wikipedia)

Es decir, resumidamente: el coeficiente de determinación (coeficiente de correlación al cuadrado) mide la bondad del ajuste de la recta a los datos.

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

summary(modelo_lineal)$r.squared 


```

Se observa que el coeficiente es muy proximo a cero. Esto significa que el modelo tiene muy poca capacidad predictiva.



# Contrastes de hipótesis: ¿En valor esperado podemos concluir que no hay infidelidad o sí? 

> Escribir la hipótesis nula y la hipótesis alternativa.

Hipótesis nula: Ho : no hay infidelidad.Es decir, los datos provienen de una poblacion cuya media es cero.
Hipotesis alternativa: H1: si hay infidelidad. Los datos contienen evidencia estadística de que la me dia de la población es distinta de cero.


>  Recordamos  que  no  conocemos  la  Varianza  poblacional.  Con  un  nivel  de  confianza  del  99%,  ¿Se rechaza o no la H0? Razonar sobre el resultado. 

Para esto nos valemos de la funcion t.test. Esta nos ayuda a realizar el contraste de hipótesis

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}

sol.test=t.test(X$naffairs ,mu=0,alternative= "two.sided" ,conf.level=0.99)
#Resumen del test
sol.test
```


El análisis es claro. La hiṕotesis nula es rechazada, siendo la verdadera media de la población mayor a cero.


> Repetir el cálculo para un nivel de confianza del 95%. 

```{r,eval=TRUE,echo=TRUE,warning=FALSE, message=FALSE}
sol.test=t.test(X$naffairs ,mu=0,alternative= "two.sided" ,conf.level=0.95)
#Resumen del test
sol.test
```
Se mantiene el mismo resultado que en el ejercicio anterior. La hipótesis nula vuelve a ser rechazada.
> Razonar sobre el resultado comparando los niveles de confianza de 95% y 99%. 

Observamos los siguientes intervalos respectivamente:

99%: [2.281355 , 3.532599] 
955: [2.432049, 3.381905].

Como vemos, el intervalo al 99% es más largo. 


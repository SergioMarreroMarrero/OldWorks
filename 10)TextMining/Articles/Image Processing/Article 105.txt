A Framework of Joint Graph Embedding and Sparse Regression for Dimensionality Reduction,

# Over the past few decades, a large number of algorithms have been developed for dimensionality reduction. Despite the different motivations of these algorithms, they can be interpreted by a common framework known as graph embedding. In order to explore the significant features of data, some sparse regression algorithms have been proposed based on graph embedding. However, the problem is that these algorithms include two separate steps: (1) embedding learning and (2) sparse regression. Thus their performance is largely determined by the effectiveness of the constructed graph. In this paper, we present a framework by combining the objective functions of graph embedding and sparse regression so that embedding learning and sparse regression can be jointly implemented and optimized, instead of simply using the graph spectral for sparse regression. By the proposed framework, supervised, semisupervised, and unsupervised learning algorithms could be unified. Furthermore, we analyze two situations of the optimization problem for the proposed framework. By adopting an â„“2,1-norm regularization for the proposed framework, it can perform feature selection and subspace learning simultaneously. Experiments on seven standard databases demonstrate that joint graph embedding and sparse regression method can significantly improve the recognition performance and consistently outperform the sparse regression method.

{feature selection;graph theory;learning (artificial intelligence);optimisation;regression analysis;L2,1-norm regularization;data features;embedding learning;feature selection;joint graph embedding-and-sparse regression method;objective functions;optimization problem;recognition performance improvement;semisupervised learning algorithm;standard databases;subspace learning;unsupervised learning algorithm;Algorithm design and analysis;Educational institutions;Electronic mail;Joints;Optimization;Principal component analysis;Vectors;$L_{2, 1}$ -norm;Graph embedding;feature selection;sparse regression;subspace learning},




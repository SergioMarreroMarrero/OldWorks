Multi-Task Pose-Invariant Face Recognition,

# Face images captured in unconstrained environments usually contain significant pose variation, which dramatically degrades the performance of algorithms designed to recognize frontal faces. This paper proposes a novel face identification framework capable of handling the full range of pose variations within ±90° of yaw. The proposed framework first transforms the original pose-invariant face recognition problem into a partial frontal face recognition problem. A robust patch-based face representation scheme is then developed to represent the synthesized partial frontal faces. For each patch, a transformation dictionary is learnt under the proposed multi-task learning scheme. The transformation dictionary transforms the features of different poses into a discriminative subspace. Finally, face matching is performed at patch level rather than at the holistic level. Extensive and systematic experimentation on FERET, CMU-PIE, and Multi-PIE databases shows that the proposed method consistently outperforms single-task-based baselines as well as state-of-the-art methods for the pose problem. We further extend the proposed algorithm for the unconstrained face verification problem and achieve top-level performance on the challenging LFW data set.

{face recognition;image matching;image representation;learning (artificial intelligence);pose estimation;CMU-PIE databases;FERET databases;LFW data set;face identification framework;face images;face matching;multiPIE databases;multitask learning scheme;multitask pose-invariant face recognition problem;partial frontal face recognition problem;pose variation;robust patch-based face representation scheme;single-task-based baselines;synthesized partial frontal faces;transformation dictionary;Dictionaries;Face;Face recognition;Feature extraction;Shape;Solid modeling;Three-dimensional displays;Pose-invariant face recognition;multi-task learning;partial face recognition},




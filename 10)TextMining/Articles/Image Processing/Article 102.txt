Scene Text Deblurring Using Text-Specific Multiscale Dictionaries,

# Texts in natural scenes carry critical semantic clues for understanding images. When capturing natural scene images, especially by handheld cameras, a common artifact, i.e., blur, frequently happens. To improve the visual quality of such images, deblurring techniques are desired, which also play an important role in character recognition and image understanding. In this paper, we study the problem of recovering the clear scene text by exploiting the text field characteristics. A series of text-specific multiscale dictionaries (TMD) and a natural scene dictionary is learned for separately modeling the priors on the text and nontext fields. The TMD-based text field reconstruction helps to deal with the different scales of strings in a blurry image effectively. Furthermore, an adaptive version of nonuniform deblurring method is proposed to efficiently solve the real-world spatially varying problem. Dictionary learning allows more flexible modeling with respect to the text field property, and the combination with the nonuniform method is more appropriate in real situations where blur kernel sizes are depth dependent. Experimental results show that the proposed method achieves the deblurring results with better visual quality than the state-of-the-art methods.

{cameras;character recognition;image capture;image reconstruction;image restoration;natural scenes;text detection;TMD-based text field reconstruction;character recognition;handheld camera;image deblurring technique;image understanding;image visual quality improve;natural scene dictionary;natural scene image capture;nonuniform deblurring method adaptive version;scene text deblurring;spatially varying problem;text-specific multiscale dictionary learning;Cameras;Dictionaries;Image restoration;Kernel;Robustness;Training;Visualization;Scene text;multi-scale dictionaries;non-unifrom deblurring;text localization},




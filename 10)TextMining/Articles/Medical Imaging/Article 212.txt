Detecting Surgical Tools by Modelling Local Appearance and Global Shape,

# Detecting tools in surgical videos is an important ingredient for context-aware computer-assisted surgical systems. To this end, we present a new surgical tool detection dataset and a method for joint tool detection and pose estimation in 2d images. Our two-stage pipeline is data-driven and relaxes strong assumptions made by previous works regarding the geometry, number, and position of tools in the image. The first stage classifies each pixel based on local appearance only, while the second stage evaluates a tool-specific shape template to enforce global shape. Both local appearance and global shape are learned from training data. Our method is validated on a new surgical tool dataset of 2 476 images from neurosurgical microscopes, which is made freely available. It improves over existing datasets in size, diversity and detail of annotation. We show that our method significantly improves over competitive baselines from the computer vision field. We achieve 15% detection miss-rate at 10-1 false positives per image (for the suction tube) over our surgical tool dataset. Results indicate that performing semantic labelling as an intermediate task is key for high quality detection.

{computer vision;image classification;learning (artificial intelligence);medical image processing;optical microscopy;pose estimation;surgery;computer vision field;context-aware computer-assisted surgical systems;global shape;joint tool detection;local appearance;neurosurgical microscopes;pixel classification;pose estimation;semantic labelling;suction tube;surgical tool detection dataset;surgical videos;tool-specific shape template;Instruments;Labeling;Semantics;Shape;Support vector machines;Surgery;Videos;Microscope images;object detection;surgical tools;template matching},



